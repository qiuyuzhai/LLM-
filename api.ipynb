{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tMyVA6SlDrLn"
      },
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import uvicorn\n",
        "import nest_asyncio  # 关键：强制兼容事件循环"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4Ra9nOoLGP5u"
      },
      "outputs": [],
      "source": [
        "# 核心操作：让所有异步代码兼容 Colab 已有的事件循环\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TJH3v-d_Dw8H"
      },
      "outputs": [],
      "source": [
        "# 初始化 FastAPI 应用\n",
        "app = FastAPI(\n",
        "    title=\"BERT-MRPC 语义匹配 API\",\n",
        "    description=\"输入两个英文句子，返回是否语义相似的预测结果（基于 MRPC 数据集训练）\",\n",
        "    version=\"1.0.0\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RNYeeEEAD8AB"
      },
      "outputs": [],
      "source": [
        "# 定义 API 请求格式\n",
        "class SemanticMatchRequest(BaseModel):\n",
        "    text1: str  # 第一个英文句子（必填）\n",
        "    text2: str  # 第二个英文句子（必填）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHb4a8s5EKab",
        "outputId": "883933fe-3179-4ac7-c8e6-e596dc42d9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型加载完成！当前使用设备：cpu\n"
          ]
        }
      ],
      "source": [
        "# 加载训练好的 BERT-MRPC 模型和分词器\n",
        "\n",
        "MODEL_CHECKPOINT_PATH = \"/content/drive/MyDrive/bert-mrpc-results/checkpoint-690\"\n",
        "\n",
        "# 加载分词器（和训练时一致，从 Checkpoint 路径加载）\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_CHECKPOINT_PATH)\n",
        "\n",
        "# 加载模型（自动加载训练好的权重）\n",
        "model = BertForSequenceClassification.from_pretrained(MODEL_CHECKPOINT_PATH)\n",
        "\n",
        "# 切换为推理模式（关闭训练时的 Dropout、BatchNorm 等）\n",
        "model.eval()\n",
        "\n",
        "# 自动使用 GPU（Colab 已配置 GPU，加速推理）\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(f\"模型加载完成！当前使用设备：{device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CliK6D24DgrA"
      },
      "outputs": [],
      "source": [
        "# 核心 API 接口（同步函数，无异步冲突）\n",
        "@app.post(\"/predict_semantic_match\")\n",
        "def predict_semantic_match(request: SemanticMatchRequest):\n",
        "    # 分词编码\n",
        "    encoded_inputs = tokenizer(\n",
        "        request.text1, request.text2,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    ).to(device)\n",
        "\n",
        "    # 推理\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "        probabilities = torch.softmax(outputs.logits, dim=1)\n",
        "        pred_label = torch.argmax(probabilities, dim=1).item()\n",
        "        pred_confidence = probabilities[0][pred_label].item()\n",
        "\n",
        "    # 返回结果\n",
        "    return {\n",
        "        \"status\": \"success\",\n",
        "        \"input\": {\"text1\": request.text1, \"text2\": request.text2},\n",
        "        \"prediction\": {\n",
        "            \"label\": pred_label,\n",
        "            \"label_desc\": \"语义相似\" if pred_label == 1 else \"语义不相似\",\n",
        "            \"confidence\": round(pred_confidence, 4),\n",
        "            \"probabilities\": {\n",
        "                \"不相似\": round(probabilities[0][0].item(), 4),\n",
        "                \"相似\": round(probabilities[0][1].item(), 4)\n",
        "            }\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 启动 API 服务（Colab 兼容模式）\n",
        "if __name__ == \"__main__\":\n",
        "    # 关键配置：使用 syncio 循环 + 单工作进程，彻底避免异步冲突\n",
        "    uvicorn.run(\n",
        "        app=app,\n",
        "        host=\"0.0.0.0\",\n",
        "        port=8000,\n",
        "        log_level=\"info\",\n",
        "        workers=1,\n",
        "        loop=\"syncio\"  # 强制使用同步循环，完全绕开 asyncio 冲突\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
